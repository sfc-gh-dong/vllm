spec:
  containers:
    - name: streamlit-container
      image: <image_repository_url>/streamlit
      env:
        OPENAI_API_BASE: http://llama:8000/v1
        MODEL: meta-llama/Llama-2-7b-chat-hf
      resources:
        requests:
          memory: 2G
          cpu: 0.5
          nvidia.com/gpu: 1
        limits:
          memory: 4G
          nvidia.com/gpu: 1
  endpoints:
    - name: chat
      port: 8501
      public: true

